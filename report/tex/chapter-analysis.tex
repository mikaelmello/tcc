A área de aprendizagem de máquina é extensa e diversa, modelos são em sua maioria desenvolvidos de forma personalizada para um problema único que buscam resolver. Esta diversidade é refletida na atual literatura sobre o uso de ML em EONs. Pesquisas como \cite{eon_ml_survey_2020} e \cite{8527529} mostram as diversas aplicações em diferentes problemas de EONs, apesar da pesquisa na área estar em sua infância.

Ao propor soluções que busquem auxiliar pesquisadores no uso de ML em simuladores, é necessário considerar os diversos casos de uso e suas características, fundamentais para definir a importância de fatores como desempenho do tempo de execução, facilidade de execução, disponibilidade da GPU, entre outros. Para isto, este trabalho focará suas contribuições em duas categorias, propostas de integração focadas em flexibilidade e facilidade de uso do usuário e propostas de integração focadas em um melhor desempenho na execução dos modelos.

\section{Flexibilidade}

No campo de aprendizagem de máquina, é comum que haja um constante refinamento de modelos em desenvolvimento, havendo várias iterações de testes e modificações de parâmetros de modo a maximizar o desempenho do modelo, avaliado em métricas apropriadas. Nestes casos, uma integração em que o pesquisador precisa constantemente exportar o modelo para carregá-lo em um simulador acaba se tornando trabalhosa. Além de exportar o modelo, ainda seria necessário modificar o simulador, possivelmente desenvolvido em uma linguagem não dominada pelo pesquisador, para que colete métricas relevantes ao processo de desenvolvimento do modelo.

Assim, a implementação de interfaces genéricas sde comunicação em simuladores é uma boa alternativa para pesquisadores que desejam manter o controle sobre o ambiente de desenvolvimento e execução de seus modelos de aprendizagem de máquina e ainda assim integrá-los facilmente com simuladores.

Nesta solução, o simulador é programado para buscar a inferência de um modelo por meio de uma interface pré-definida, como por exemplo chamadas em HTTP para um servidor configurado, e o pesquisador é responsável por implementar a interface no serviço que executa o modelo, neste exemplo um servidor HTTP. Assim, o pesquuisador mantém o controle sobre o ambiente deste modelo, sendo capaz de coletar quaisquer métricas relevantes de execução como os valores de entrada e saída, tempo de execução, entre outros, e sem precisar constantemente exportar o modelo e carregá-lo no simulador a cada rodada de testes.

Sua principal desvantagem consiste em maiores tempos de execução do modelo, do ponto de vista do simualdor. Isto acontece pela sobrecarga de operações para transferir os dados de entrada e saída do modelo entre processos além da latência presente na comunicação entre serviços. Esta sobrecarga adicional de tempo de execução pode ser significativa ou não, dependendo de vários fatores acerca do estudo sendo realizado e do modelo sendo desenvolvido.

\section{Desempenho}

A solução com foco em desempenho busca diminuir o tempo total de execução de modelos, o que torna importante que os modelos possam ser executados de forma nativa pelo simulador uma vez que isto elimina a sobrecarga de tempo por comunicação externa.

Para simuladores desenvolvidos em Java, vimos no capítulo \ref{chapter-deploy} que para o modelo selecionado, executá-lo com a biblioteca Deeplearning4j sem o uso de GPU exibiu o melhor desempenho. A biblioteca ONNX Runtime, apesar de mais lenta, também é atrativa por permitir a importação de modelos no formato ONNX, um formato popular e capaz de ser o alvo de conversão de diversos outros formatos existentes na literatura.

Em Python, a biblioteca ONNX Runtime com o uso de GPU exibiu um desempenho tão bom quanto OpenCV sem o uso de GPU. Ambas combinações possuem suas vantagens e desvantagens em relação a facilidade e flexibilidade no uso: OpenCV é voltada para uso na área de visão computacional, o que torna o uso dela em outros contextos sub-óptimo se ela não for a melhor escolha no quesito desempenho; ONNX Runtime precisa do uso da GPU para ter um desempenho tão bom quanto OpenCV com este modelo, porém tem suporte para fácil configuração de uso da GPU e uma API mais amigável.

\section{Contribuições ao ONS}

Este trabalho oferece uma proposta de implementação para o \acrfull{ONS}, com implementações para interfaces e classes que definem a arquitetura do uso de modelos de aprendizagem de máquina no simulador.

No quesito flexibilidade, foi implementada uma classe genérica de comunicação HTTP configurável por 3 parâmetros: tipo dos dados de entrada do modelo, tipo dos dados de saída do modelo e a URL em que o modelo está sendo servido. Esta classe fornece um método para execução dos modelos, que recebe a entrada do tipo pré-definido, a serializa e faz a requisição para a URL. A resposta da requisição deve ser em JSON e é então desserializada de modo a obter o valor encapsulado e retornado ao chamador da função.

No quesito desempenho, são propostas implementações de interfaces e classes para a execução nativa de modelos. A princípio, foram implementados os fluxos de carregamento de modelos nas bibliotecas Deeplearning4j e ONNX Runtime.

Por fim, foram implementadas integrações do modelo utilizado na avaliação de desempenho deste trabalho com as 3 contribuições aquui presentes: carregamento e execução do modelo com as bibliotecas Deeplearning4j e ONNX Runtime, além do uso da interface focada em flexibilidade que fará requisições para um servidor local. A classe \texttt{FF\_Classifier} possui a implementação de um algoritmo RSA que, além de definir a ação sobre a chegada de um novo fluxo, envia o estado da topologia da rede para as 3 implementações e imprime suas saídas, a classificação do algoritmo RSA, e o tempo levado na execução de cada uma delas.

Com estas contribuições, espera-se que atuais usuários do ONS possam utilizar modelos de ML pré-treinados em suas simulações, e que pesquisadores de ML na área de EONs sintam-se incentivados a utilizar o ONS para auxiliar-los em suas pesquisas.