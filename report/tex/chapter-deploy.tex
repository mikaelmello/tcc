Este capítulo tem como objetivo apresentar a metodologia da avaliação de desempenho dos diferentes sistemas de inferência propostos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motivação}%

Avaliações de desempenho são importantes na busca pelo máximo desempenho de um sistema com os recursos disponíveis. Seus resultados auxiliam tanto nas decisões de escolha de diferentes sistemas ou simplesmente entender o funcionamento de um sistema já existente.

Devido à grande diversidade de tipos de sistemas, não existe um procedimento padrão comum em que seja possível analisar eficientemente um sistema qualquer. Por este motivo é necessário conhecer o sistema a ser avaliado e escolher as métricas, carga de trabalho e técnicas de avaliação apropriadas. \cite{jain1991art}

O sistema a ser avaliado é a classificação de algoritmos de alocação de recursos em EONs no ONS. O ONS irá realizar um grande número de chamadas de inferência do modelo de redes neurais profundas, aqui chamado de classificador. O objetivo da avaliação de desempenho é escolher um conjunto de fatores que minimizem a taxa de erro do resultado das inferências, a precisão, e o tempo total percorrido durante o processo de inferência, o tempo de inferência.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Metodologia}%

De acordo com Raj Jain \cite{jain1991art}, há três métodos de avaliação de desempenho: modelagem analítica, simulação e medição.

O sistema a ser avaliado, devido a presença de modelos de redes neurais profundas, é complexo o suficiente para tornar a modelagem analítica inviável. Além disso, a tarefa de integrar o ONS com os diferentes sistemas a serem comparados exigir bastante tempo e trabalho, diminuindo as vantagens de realizar uma medição. Por estes motivos, a avaliação de desempenho é realizada por meio de simulações.

A simulação se dá por meio de um programa Java, simulando um módulo de classificação do ONS, que realiza chamadas contínuas ao serviço implementado pelos sistemas de inferência avaliados, o classificador. Os parâmetros das chamadas são amostras de execuções reais do simulador onde o sistema de inferência seria utilizado e o resultado das classificações são representações reais de valores esperados pelo ONS.

Quando o sistema de inferência sendo avaliado possuir como fator a linguagem de programação Java, a inferência será feita de forma embutida no programa Java de simulação. Quando a linguagem de programação for Python, o programa de simulação irá se comunicar com o sistema em Python por meio de Unix Sockets \cite{unix}. De modo a analisar o impacto da latência da comunicação entre processos, o tempo de inferência dos sistemas feitos em Python também será analisado sem a comunicação com o programa Java.

Neste estudo, com o objetivo de analisar o impacto de cada um dos fatores descritos na seção \ref{paramsfactors}, será realizado um desenho experimental do tipo fatorial completo, onde é realizada uma simulação para cada combinação diferente dos fatores. O principal benefício deste tipo de desenho experimental é a possibilidade de analisar o impacto de cada um dos fatores assim como impactos com certas combinações de fatores.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Métricas}

Em uma execução comum de uma simulação do ONS, são realizadas entre 10 mil a 1 milhão chamadas ao classificador, responsáveis por classificar a topologia da rede em categorias pré-definidas. Este comportamento torna importantes as seguintes métricas de desempenho:

\begin{itemize}
  \item \textbf{Tempo de inferência} - o tempo total percorrido desde a chamada do serviço de classificação até a obtenção do resultado. Pelo alto número de chamadas realizadas por uma execução do ONS, é crucial que cada chamada tome o menor tempo possível para diminuir o tempo de execução total do ONS;
  \item \textbf{Acurácia} - taxa de corretude dos resultados das chamadas de classificação, comparado com o resultado esperado. O resultado de uma classificação impacta diretamente as ações da simulação sendo executada no ONS, tornando importante avaliar se certas combinações de fatores do sistema diminuem a acurácia do serviço de inferência para um valor abaixo do esperado.
\end{itemize}

\section{Parâmetros e Fatores}
\label{paramsfactors}

Em uma análise de desempenho, é importante estar ciente dos parâmetros do sistema que podem afetar o desempenho do serviço \cite{jain1991art}. Os parâmetros são categorizados de duas maneiras: os que serão variados durante a avaliação e os que não serão. Os variados são chamados de \textbf{fatores} e seus valores de \textbf{níveis}.

De acordo com a definição do sistema e as métricas de avaliação, são conhecidos os seguintes parâmetros com possível impacto nos resultados: velocidade da CPU; velocidade da GPU; número e tamanho de parâmetros de chamada; tipo de serialização do modelo de ML; linguagem de programação e biblioteca usada para a inferência; uso da CPU ou da GPU para a inferência; modelo de ML usado na inferência; e outras cargas diversas na máquina onde a simulação é feita. Nesta avaliação, os seguintes fatores e seus níveis são escolhidos:

\begin{itemize}
  \item Uso ou não uso da GPU - modelos de redes neurais profundas, dependendo de suas características e como são utilizados, podem beneficiar-se ou não da disponibilidade de uma GPU;
  \item Linguagem de programação usada para a inferência - Java, representando um sistema de inferência embutido na implementação do ONS, e Python, um serviço externo que se comunicaria com o ONS por meio de Unix Sockets; % TODO 1: detalhar melhor
  \item Biblioteca usada para inferência - fator relacionado com a linguagem de programação, pois algumas bibliotecas não estão disponíveis para ambas linguagens. Serão simuladas execuções usando as bibliotecas ONNX \cite{onnx2019} (Java e Python), Tensorflow Lite (Python), Tensorflow (Java) e deeplearning4j \cite{deeplearning4j} (Java).
  \item Número e tamanho de parâmetros da chamada - também chamado de carga de trabalho, composto por 3 diferentes conjuntos de entradas representativas de um uso real do ONS, categorizados como alto, médio e baixo número de chamadas;
  \item Modelo DNN - serão usados dois modelos de redes neurais profundas já treinados: Deep-Quality-RSA \cite{deep_quality_rsa} e Deep-Quality-RSA-2 \cite{deep_quality_rsa}.
\end{itemize}

Tendo em vista a utilização de um desenho fatorial completo, observa-se que todas as combinações destes 5 fatores resulta em 72 simulações diferentes.

\section{Carga de Trabalho}

É importante que a simulação seja o mais fiel possível à execução real do sistema. Assim, a carga de trabalho selecionada para a simulação é coletada de execuções prévias do ONS que também envolvem chamadas a um classificador de algoritmos de alocação de recursos em EONs, utilizadas em outras pesquisas. Sendo composta por 3 amostras diferentes:

\begin{itemize}
  \item Carga baixa - conjunto de parâmetros de chamada com aproximadamente dez mil elementos, representando uma execução do ONS com poucas chamadas.
  \item Carga média - conjunto de parâmetros de chamada com aproximadamente cem mil elementos, representando uma execução do ONS com um número significativo de chamadas.
  \item Carga alta - conjunto de parâmetros de chamada com aproximadamente um milhão elementos, representando uma execução do ONS que envolve um alto número de chamadas ao classificador.
\end{itemize}
